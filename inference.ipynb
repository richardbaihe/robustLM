{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd075cb0a935ebddde92bbadecbf6cd5ab11b8a339ec08f7225899b0a00029c7eca",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# LM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = [\n",
    "        \"--data\", \"/home/baihe/datasets/LM_data/wikitext-103/\",\n",
    "        \"--dataset\", \"wt103\",\n",
    "        \"--split\", \"valid\",\n",
    "        \"--batch_size\", \"64\",\n",
    "        \"--tgt_len\", \"150\",\n",
    "        \"--cuda\", \n",
    "        \"--work_dir\", \"/home/baihe/projects/Dynasparse-transformer/wiki103/0710/base_trans\",\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading cached dataset...\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'mem_transformer.MemTransformerLM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.container.ParameterList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'mem_transformer.RelPartialLearnableDecoderLayer' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'mem_transformer.RelPartialLearnableMultiHeadAttn' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.normalization.LayerNorm' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/baihe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'utils.proj_adaptive_softmax.ProjectedAdaptiveLogSoftmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "Evaluating with bsz 64 tgt_len 150 ext_len 0 mem_len 0 clamp_len -1\n",
      "/home/baihe/projects/Dynasparse-transformer/utils/proj_adaptive_softmax.py:124: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  indices_i = mask_i.nonzero().squeeze()\n",
      "Time : 3.43s, 149.31ms/segment\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os, sys\n",
    "\n",
    "import torch\n",
    "\n",
    "from data_utils import get_lm_corpus\n",
    "from mem_transformer import MemTransformerLM\n",
    "from utils.exp_utils import get_logger\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Transformer Language Model')\n",
    "parser.add_argument('--data', type=str, default='../data/wikitext-103',\n",
    "                    help='location of the data corpus')\n",
    "parser.add_argument('--dataset', type=str, default='wt103',\n",
    "                    choices=['wt103', 'lm1b', 'enwik8', 'text8'],\n",
    "                    help='dataset name')\n",
    "parser.add_argument('--split', type=str, default='all',\n",
    "                    choices=['all', 'valid', 'test'],\n",
    "                    help='which split to evaluate')\n",
    "parser.add_argument('--batch_size', type=int, default=10,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--tgt_len', type=int, default=5,\n",
    "                    help='number of tokens to predict')\n",
    "parser.add_argument('--ext_len', type=int, default=0,\n",
    "                    help='length of the extended context')\n",
    "parser.add_argument('--mem_len', type=int, default=0,\n",
    "                    help='length of the retained previous heads')\n",
    "parser.add_argument('--clamp_len', type=int, default=-1,\n",
    "                    help='max positional embedding index')\n",
    "parser.add_argument('--cuda', action='store_true',\n",
    "                    help='use CUDA')\n",
    "parser.add_argument('--work_dir', type=str, required=True,\n",
    "                    help='path to the work_dir')\n",
    "parser.add_argument('--no_log', action='store_true',\n",
    "                    help='do not log the eval result')\n",
    "parser.add_argument('--same_length', action='store_true',\n",
    "                    help='set same length attention with masking')\n",
    "parser.add_argument('--sega', action='store_true',\n",
    "                    help='sega or not')\n",
    "parser.add_argument('--sparse_mode', type=str, default='none',\n",
    "                    help='spare mode for longformer')\n",
    "args = parser.parse_args(args_list)\n",
    "assert args.ext_len >= 0, 'extended context length must be non-negative'\n",
    "args.sent_eos=False\n",
    "if 'eos' in args.sparse_mode:\n",
    "    args.sent_eos=True\n",
    "args.compressed_mem = False\n",
    "if 'compress' in args.sparse_mode:\n",
    "    args.compressed_mem=True\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "args.work_dir = '{}-{}'.format(args.work_dir, args.dataset)\n",
    "# Get logger\n",
    "logging = get_logger(os.path.join(args.work_dir, 'log.txt'),\n",
    "                     log_=not args.no_log)\n",
    "\n",
    "# Load dataset\n",
    "corpus = get_lm_corpus(args.data, args.dataset, sega=args.sega, sent_eos=args.sent_eos)\n",
    "ntokens = len(corpus.vocab)\n",
    "\n",
    "va_iter = corpus.get_iterator('valid', args.batch_size, args.tgt_len,\n",
    "    device=device, ext_len=args.ext_len)\n",
    "te_iter = corpus.get_iterator('test', args.batch_size, args.tgt_len,\n",
    "    device=device, ext_len=args.ext_len)\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(os.path.join(args.work_dir, 'model.pt'), 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "model.backward_compatible()\n",
    "model = model.to(device)\n",
    "\n",
    "logging('Evaluating with bsz {} tgt_len {} ext_len {} mem_len {} clamp_len {}'.format(\n",
    "       args.batch_size, args.tgt_len, args.ext_len, args.mem_len, args.clamp_len))\n",
    "\n",
    "model.reset_length(args.tgt_len, args.ext_len, args.mem_len)\n",
    "if args.clamp_len > 0:\n",
    "    model.clamp_len = args.clamp_len\n",
    "if args.same_length:\n",
    "    model.same_length = True\n",
    "\n",
    "###############################################################################\n",
    "# Evaluation code\n",
    "###############################################################################\n",
    "\n",
    "def get_all_props(model, data, target, *mems):\n",
    "    if not mems: mems = model.init_mems()\n",
    "\n",
    "    tgt_len = target.size(0)\n",
    "    hidden, new_mems = model._forward(data, mems=mems)\n",
    "\n",
    "    pred_hid = hidden[-tgt_len:]\n",
    "    probs = model.crit.get_all_props(pred_hid.view(-1, pred_hid.size(-1)), target.view(-1))\n",
    "\n",
    "    if new_mems is None:\n",
    "        return [probs]\n",
    "    else:\n",
    "        return [probs] + new_mems\n",
    "\n",
    "def get_nll(model, data, target, *mems):\n",
    "    if not mems: mems = model.init_mems()\n",
    "\n",
    "    tgt_len = target.size(0)\n",
    "    hidden, new_mems = model._forward(data, mems=mems)\n",
    "\n",
    "    pred_hid = hidden[-tgt_len:]\n",
    "    nll = model.crit(pred_hid.view(-1, pred_hid.size(-1)), target.view(-1))\n",
    "    nll = nll.view(tgt_len, -1)\n",
    "    if new_mems is None:\n",
    "        return [nll]\n",
    "    else:\n",
    "        return [nll] + new_mems\n",
    "def evaluate(eval_iter):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    all_words, all_probs, all_targets = [],[],[]\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        mems = tuple()\n",
    "        for idx, (data, target, seq_len) in enumerate(eval_iter):\n",
    "            ret = get_nll(model,data, target, *mems)\n",
    "            loss = ret[0]#, ret[1]\n",
    "            # all_probs.append(loss)\n",
    "            # all_targets.append(target)\n",
    "            all_probs.extend(loss.tolist())\n",
    "            all_targets.extend(target.view(-1).tolist())\n",
    "            mems = ret[1:]\n",
    "        total_time = time.time() - start_time\n",
    "    logging('Time : {:.2f}s, {:.2f}ms/segment'.format(\n",
    "            total_time, 1000 * total_time / (idx+1)))\n",
    "    return all_probs, all_targets#all_words, \n",
    "\n",
    "all_probs, all_targets = evaluate(va_iter)\n",
    "print('done')\n",
    "\n",
    "# all_probs = torch.cat(all_probs).cpu().numpy()\n",
    "# all_targets = torch.cat(all_targets).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_threshold = np.sort(all_probs)[int(len(all_targets)*0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_over_threshold = np.array(all_targets)[np.array(all_probs)>nll_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "108767"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "len(nll_over_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  4185,   4187,   4187, ..., 263386, 263697, 264664])"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "np.sort(nll_over_threshold)[90000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Security',\n",
       " 'features',\n",
       " 'and',\n",
       " 'to',\n",
       " 'adheres',\n",
       " 'Biggs',\n",
       " 'both',\n",
       " '<eos>',\n",
       " 'also',\n",
       " ',',\n",
       " 'was',\n",
       " 'southeast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'and',\n",
       " 'a',\n",
       " 'January',\n",
       " 'the',\n",
       " 'in',\n",
       " 'of',\n",
       " 'the',\n",
       " 'gammarus',\n",
       " 're',\n",
       " 'Angel',\n",
       " 'Benchmark',\n",
       " 'think',\n",
       " 'is',\n",
       " 'Myanmar',\n",
       " 'has',\n",
       " 'the',\n",
       " '\"',\n",
       " 'the',\n",
       " ',',\n",
       " ',',\n",
       " '=',\n",
       " 'post',\n",
       " 'to',\n",
       " ',',\n",
       " 'near',\n",
       " 'the',\n",
       " 'used',\n",
       " 'For',\n",
       " 'ruins',\n",
       " 'layout',\n",
       " 'and',\n",
       " '9',\n",
       " \"'t\",\n",
       " 'Beckham',\n",
       " '.',\n",
       " 'before',\n",
       " 'rope',\n",
       " 'following',\n",
       " 'backstage',\n",
       " 'of',\n",
       " '.',\n",
       " 'character',\n",
       " ',',\n",
       " 'create',\n",
       " '8',\n",
       " 'Columbus',\n",
       " 'Winston',\n",
       " 'others',\n",
       " 'been',\n",
       " 'that',\n",
       " 'September',\n",
       " 'gamers',\n",
       " 'the',\n",
       " '\"',\n",
       " 'a',\n",
       " 'New',\n",
       " 'Jack',\n",
       " 'the',\n",
       " '.',\n",
       " 'Kyle',\n",
       " '.',\n",
       " 'former',\n",
       " 'there',\n",
       " '\"',\n",
       " 'Burmese',\n",
       " '<eos>',\n",
       " 'proven',\n",
       " '7',\n",
       " 'the',\n",
       " 'In',\n",
       " 'Battalion',\n",
       " 'chases',\n",
       " '.',\n",
       " 'was',\n",
       " 'the',\n",
       " 'The',\n",
       " 'interaction',\n",
       " 'IGN',\n",
       " '.',\n",
       " 'Early',\n",
       " 'the',\n",
       " 'Subsequent',\n",
       " '1880s',\n",
       " 'the',\n",
       " 'white',\n",
       " 'integrating',\n",
       " 'off',\n",
       " ',',\n",
       " 'navigation',\n",
       " 'Opera',\n",
       " 'CW',\n",
       " 'Early',\n",
       " 'life',\n",
       " 'team',\n",
       " '26',\n",
       " ',',\n",
       " '.',\n",
       " 'so',\n",
       " ';',\n",
       " 'support',\n",
       " 'crescent',\n",
       " 'flights',\n",
       " 'Off',\n",
       " 'of',\n",
       " 'that',\n",
       " 'in',\n",
       " '.',\n",
       " 'Excavations',\n",
       " '=',\n",
       " 'family',\n",
       " \"'s\",\n",
       " 'Express',\n",
       " 'our',\n",
       " 'German',\n",
       " '21',\n",
       " 'him',\n",
       " 'sculpture',\n",
       " 'Christopher',\n",
       " 'of',\n",
       " 'that',\n",
       " 'the',\n",
       " 'Andrew',\n",
       " 'battle',\n",
       " 'Movement',\n",
       " 'referee',\n",
       " 'how',\n",
       " 'in',\n",
       " '90',\n",
       " 'Shikamaru',\n",
       " 'was',\n",
       " '2',\n",
       " 'Mycenaceae',\n",
       " '<unk>',\n",
       " '1285',\n",
       " 'Japanese',\n",
       " 'denied',\n",
       " 'the',\n",
       " 'and',\n",
       " 'God',\n",
       " 'dance',\n",
       " 'galvanised',\n",
       " 'Overtoom',\n",
       " '—',\n",
       " 'punished',\n",
       " 'way',\n",
       " 'bass',\n",
       " 'Wing',\n",
       " '.',\n",
       " 'coordinator',\n",
       " 'that',\n",
       " 'E',\n",
       " 'fencing',\n",
       " 'city',\n",
       " 'parts',\n",
       " 'the',\n",
       " 'Royal',\n",
       " '<eos>',\n",
       " 'Allen',\n",
       " '\"',\n",
       " ',',\n",
       " 'to',\n",
       " 'the',\n",
       " 'one',\n",
       " 'found',\n",
       " 'a',\n",
       " 'opening',\n",
       " 'his',\n",
       " 'to',\n",
       " 'Hongorai',\n",
       " 'technician',\n",
       " 'Military',\n",
       " 'would',\n",
       " 'silicon',\n",
       " '<unk>',\n",
       " 'the',\n",
       " '1889',\n",
       " '<eos>',\n",
       " 'paintings',\n",
       " 'Groups',\n",
       " 'the',\n",
       " 'make',\n",
       " '.',\n",
       " 'interfere',\n",
       " 'the',\n",
       " 'his',\n",
       " 'their',\n",
       " 'by',\n",
       " 'as',\n",
       " '23',\n",
       " 'the',\n",
       " 'way',\n",
       " 'an',\n",
       " 'Biggs',\n",
       " '<eos>',\n",
       " 'song',\n",
       " 'screwed',\n",
       " 'used',\n",
       " ',',\n",
       " '=',\n",
       " 'parents',\n",
       " 'causing',\n",
       " 'as',\n",
       " 'drums',\n",
       " 'assassination',\n",
       " 'review',\n",
       " 'over',\n",
       " 'favorite',\n",
       " 'called',\n",
       " '=',\n",
       " \"'s\",\n",
       " '.',\n",
       " 'intellectual',\n",
       " 'the',\n",
       " 'airstrip',\n",
       " 'identified',\n",
       " 'the',\n",
       " ',',\n",
       " 'from',\n",
       " '16',\n",
       " 'million',\n",
       " 'that',\n",
       " 'into',\n",
       " 'Gulf',\n",
       " 'Styles',\n",
       " 'arrangement',\n",
       " 'command',\n",
       " 'DHS',\n",
       " '29',\n",
       " 'sea',\n",
       " 'has',\n",
       " 'as',\n",
       " 'senatorial',\n",
       " 'aged',\n",
       " 'to',\n",
       " 'rapid',\n",
       " '.',\n",
       " 'General',\n",
       " '<unk>',\n",
       " 'in',\n",
       " 'of',\n",
       " 'a',\n",
       " ',',\n",
       " 'walls',\n",
       " 'was',\n",
       " 'had',\n",
       " 'Dohrn',\n",
       " 'established',\n",
       " 'he',\n",
       " 'No.',\n",
       " 'rhyolite',\n",
       " '\"',\n",
       " 'who',\n",
       " 'at',\n",
       " 'no',\n",
       " 'years',\n",
       " 'been',\n",
       " 'and',\n",
       " 'was',\n",
       " 'highway',\n",
       " 'producing',\n",
       " 'Canada',\n",
       " 'to',\n",
       " ',',\n",
       " 'and',\n",
       " 'springy',\n",
       " 'in',\n",
       " '–',\n",
       " 'annihilated',\n",
       " 'the',\n",
       " 'captured',\n",
       " 'dies',\n",
       " \"'s\",\n",
       " 'turntables',\n",
       " ',',\n",
       " 'is',\n",
       " 'km',\n",
       " '\"',\n",
       " '<eos>',\n",
       " '(',\n",
       " ',',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Tibbitt',\n",
       " '=',\n",
       " ',',\n",
       " 'that',\n",
       " 'The',\n",
       " 'as',\n",
       " 'years',\n",
       " 'of',\n",
       " 'bell',\n",
       " 'Structure',\n",
       " 'Falls',\n",
       " 'set',\n",
       " 'Styles',\n",
       " 'probation',\n",
       " 'December',\n",
       " 'referred',\n",
       " 'of',\n",
       " 'parents',\n",
       " '.',\n",
       " 'the',\n",
       " 'a',\n",
       " 'him',\n",
       " '=',\n",
       " 'color',\n",
       " 'sections',\n",
       " 'Commando',\n",
       " 'he',\n",
       " '.',\n",
       " 'more',\n",
       " 'used',\n",
       " 'to',\n",
       " 'Rothenberg',\n",
       " ',',\n",
       " 'various',\n",
       " '@-@',\n",
       " 'centre',\n",
       " 'the',\n",
       " 'became',\n",
       " 'list',\n",
       " 'involved',\n",
       " 'is',\n",
       " 'Crestview',\n",
       " '<eos>',\n",
       " 'cap',\n",
       " 'they',\n",
       " 'a',\n",
       " '8',\n",
       " 'the',\n",
       " 'to',\n",
       " 'striking',\n",
       " 'would',\n",
       " 'the',\n",
       " '<eos>',\n",
       " 'up',\n",
       " 'only',\n",
       " 'Democrats',\n",
       " 'youngest',\n",
       " 'French',\n",
       " ',',\n",
       " 'Blythe',\n",
       " '.',\n",
       " 'after',\n",
       " 'Angle',\n",
       " '<unk>',\n",
       " 'soundtrack',\n",
       " '.',\n",
       " 'developed',\n",
       " 'been',\n",
       " ',',\n",
       " 'painted',\n",
       " 'stated',\n",
       " 'during',\n",
       " 'start',\n",
       " 'who',\n",
       " 'being',\n",
       " 'as',\n",
       " ',',\n",
       " 'were',\n",
       " 'Service',\n",
       " 'celebrated',\n",
       " 'a',\n",
       " 'Billboard',\n",
       " ',',\n",
       " 'at',\n",
       " 'time',\n",
       " 'Ben',\n",
       " 'disrespectful',\n",
       " 'the',\n",
       " 'which',\n",
       " 'black',\n",
       " 'the',\n",
       " 'in',\n",
       " 'central',\n",
       " 'shear',\n",
       " 'voted',\n",
       " ',',\n",
       " 'and',\n",
       " 'there',\n",
       " 'Fans',\n",
       " 'the',\n",
       " 'Sheela',\n",
       " 'already',\n",
       " '@-@',\n",
       " 'conflicts',\n",
       " '90',\n",
       " 'sea',\n",
       " 'against',\n",
       " ',',\n",
       " '<eos>',\n",
       " 'opera',\n",
       " '5',\n",
       " 'Warner',\n",
       " 'game',\n",
       " '.',\n",
       " ',',\n",
       " ',',\n",
       " 'over',\n",
       " 'interview',\n",
       " '–',\n",
       " 'North',\n",
       " 'region',\n",
       " 'the',\n",
       " 'he',\n",
       " 'after',\n",
       " 'but',\n",
       " 'for',\n",
       " ')',\n",
       " '(',\n",
       " '.',\n",
       " 'America',\n",
       " 'the',\n",
       " 'East',\n",
       " 'salient',\n",
       " 'attended',\n",
       " 'It',\n",
       " 'Turner',\n",
       " 'Headlam',\n",
       " 'any',\n",
       " 'hosted',\n",
       " '<eos>',\n",
       " 'Richmond',\n",
       " '(',\n",
       " ',',\n",
       " '23',\n",
       " 'Michael',\n",
       " 'from',\n",
       " 'were',\n",
       " 'siege',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'coalition',\n",
       " 'local',\n",
       " 'his',\n",
       " ',',\n",
       " 'German',\n",
       " '\"',\n",
       " 'magazine',\n",
       " 'six',\n",
       " \"'s\",\n",
       " 'the',\n",
       " 'had',\n",
       " 'March',\n",
       " 'returns',\n",
       " 'Louisville',\n",
       " ',',\n",
       " 'storyboard',\n",
       " 'schools',\n",
       " 'West',\n",
       " 'jail',\n",
       " 'Things',\n",
       " 'and',\n",
       " 'some',\n",
       " 'Calvin',\n",
       " 'met',\n",
       " '372',\n",
       " 'suspected',\n",
       " 'Wynyard',\n",
       " 'include',\n",
       " 'directors',\n",
       " \"'s\",\n",
       " 'the',\n",
       " 'that',\n",
       " 'start',\n",
       " 'air',\n",
       " 'McCarty',\n",
       " ',',\n",
       " 'of',\n",
       " '.',\n",
       " 'installation',\n",
       " 'to',\n",
       " 'for',\n",
       " '<eos>',\n",
       " 'dope',\n",
       " 'Angeles',\n",
       " 'investigation',\n",
       " 'of',\n",
       " '5',\n",
       " 'to',\n",
       " ')',\n",
       " 'office',\n",
       " 'the',\n",
       " 'costs',\n",
       " 'stage',\n",
       " 'in',\n",
       " 'and',\n",
       " '<unk>',\n",
       " 'governing',\n",
       " '\"',\n",
       " 'million',\n",
       " ')',\n",
       " '1',\n",
       " 'after',\n",
       " '.',\n",
       " 'act',\n",
       " 'of',\n",
       " 'Scientologists',\n",
       " 'carried',\n",
       " '.',\n",
       " 'was',\n",
       " ',',\n",
       " 'Party',\n",
       " 'Imjin',\n",
       " 'in',\n",
       " ',',\n",
       " 'of',\n",
       " '–',\n",
       " 'the',\n",
       " 'and',\n",
       " 'a',\n",
       " 'and',\n",
       " ',',\n",
       " 'fitted',\n",
       " 'the',\n",
       " 'when',\n",
       " 'the',\n",
       " '2',\n",
       " 'is',\n",
       " 'another',\n",
       " 'the',\n",
       " '04',\n",
       " 'conducts',\n",
       " 'a',\n",
       " 'defibrillator',\n",
       " '.',\n",
       " 'he',\n",
       " 'Springfield',\n",
       " 'Styles',\n",
       " 'a',\n",
       " 'from',\n",
       " 'In',\n",
       " 'National',\n",
       " 'work',\n",
       " '.',\n",
       " 'talks',\n",
       " 'mule',\n",
       " 'was',\n",
       " 'returned',\n",
       " 'there',\n",
       " 'position',\n",
       " 'William',\n",
       " 'The',\n",
       " 'was',\n",
       " '.',\n",
       " '.',\n",
       " 'received',\n",
       " 'The',\n",
       " 'The',\n",
       " 'century',\n",
       " '.',\n",
       " '.',\n",
       " ',',\n",
       " 'in',\n",
       " 'Hill',\n",
       " 'back',\n",
       " 'own',\n",
       " 'the',\n",
       " '1st',\n",
       " 'War',\n",
       " ',',\n",
       " 'they',\n",
       " 'to',\n",
       " 'a',\n",
       " '19th',\n",
       " 'thin',\n",
       " '.',\n",
       " '1775',\n",
       " 'islands',\n",
       " 'Australian',\n",
       " 'were',\n",
       " 'than',\n",
       " 'naval',\n",
       " 'into',\n",
       " 'it',\n",
       " '<eos>',\n",
       " 'commune',\n",
       " 'gets',\n",
       " 'his',\n",
       " 'offered',\n",
       " 'scene',\n",
       " '=',\n",
       " 'rich',\n",
       " 'suspicions',\n",
       " 'participated',\n",
       " 'the',\n",
       " '.',\n",
       " 'European',\n",
       " 'up',\n",
       " 'union',\n",
       " '<unk>',\n",
       " 'general',\n",
       " 'Beatriz',\n",
       " 'a',\n",
       " 'is',\n",
       " 'the',\n",
       " 'Taivu',\n",
       " 'been',\n",
       " 'Despite',\n",
       " ',',\n",
       " 'back',\n",
       " 'Wiese',\n",
       " '.',\n",
       " '<eos>',\n",
       " 'Union',\n",
       " \"'s\",\n",
       " 'to',\n",
       " 'bass',\n",
       " 'crew',\n",
       " 'Point',\n",
       " 'low',\n",
       " 'the',\n",
       " 'to',\n",
       " 'worked',\n",
       " 'believed',\n",
       " '—',\n",
       " ',',\n",
       " 'Penrith',\n",
       " 'two',\n",
       " 'Empire',\n",
       " ',',\n",
       " 'project',\n",
       " '(',\n",
       " '.',\n",
       " 'geography',\n",
       " 'in',\n",
       " 'the',\n",
       " 'to',\n",
       " 'the',\n",
       " 'David',\n",
       " 'title',\n",
       " ',',\n",
       " 'other',\n",
       " 'assaults',\n",
       " 'its',\n",
       " '<eos>',\n",
       " 'Six',\n",
       " '<eos>',\n",
       " '.',\n",
       " 'was',\n",
       " 'for',\n",
       " 'in',\n",
       " 'mountains',\n",
       " 'cm',\n",
       " 'years',\n",
       " 'where',\n",
       " 'The',\n",
       " 'it',\n",
       " 'and',\n",
       " 'This',\n",
       " ',',\n",
       " 'programming',\n",
       " 'West',\n",
       " 'for',\n",
       " 'Joan',\n",
       " 'on',\n",
       " 'later',\n",
       " 'main',\n",
       " '.',\n",
       " 'to',\n",
       " 'two',\n",
       " 'several',\n",
       " 'H.',\n",
       " 'unwillingness',\n",
       " 'the',\n",
       " 'Beeman',\n",
       " 'Smith',\n",
       " 'the',\n",
       " 'had',\n",
       " 'crossing',\n",
       " '<eos>',\n",
       " 'top',\n",
       " 'in',\n",
       " '\"',\n",
       " 'to',\n",
       " \"'\",\n",
       " 'department',\n",
       " 'mph',\n",
       " ':',\n",
       " 'discovers',\n",
       " '1277',\n",
       " 'as',\n",
       " 'management',\n",
       " 'as',\n",
       " '.',\n",
       " '@,@',\n",
       " 'him',\n",
       " ',',\n",
       " 'his',\n",
       " 'began',\n",
       " 'Retro',\n",
       " '(',\n",
       " 'The',\n",
       " '5',\n",
       " 'impress',\n",
       " '000',\n",
       " 'designing',\n",
       " '.',\n",
       " 'a',\n",
       " 'later',\n",
       " 'by',\n",
       " 'the',\n",
       " 'training',\n",
       " 'of',\n",
       " 'are',\n",
       " '1287',\n",
       " 'Brigade',\n",
       " 'with',\n",
       " 'for',\n",
       " 'the',\n",
       " 'due',\n",
       " 'The',\n",
       " 'capabilities',\n",
       " 'number',\n",
       " 'to',\n",
       " 'strongly',\n",
       " 'may',\n",
       " 'term',\n",
       " 'law',\n",
       " 'Network',\n",
       " 'UK',\n",
       " 'hand',\n",
       " 'florescence',\n",
       " 'which',\n",
       " 'the',\n",
       " 'said',\n",
       " 'leadership',\n",
       " 'it',\n",
       " 'singer',\n",
       " 'if',\n",
       " 'grow',\n",
       " 'enforcement',\n",
       " ',',\n",
       " 'a',\n",
       " 'in',\n",
       " 'The',\n",
       " '@-@',\n",
       " 'as',\n",
       " 'not',\n",
       " 'firm',\n",
       " 'allowed',\n",
       " 'Jim',\n",
       " 'the',\n",
       " 'British',\n",
       " ',',\n",
       " '@-@',\n",
       " 'described',\n",
       " 'forcing',\n",
       " 'the',\n",
       " 'and',\n",
       " 'the',\n",
       " 'opening',\n",
       " 'by',\n",
       " '\"',\n",
       " 'in',\n",
       " ',',\n",
       " 'his',\n",
       " 'of',\n",
       " 'previously',\n",
       " 'the',\n",
       " 'known',\n",
       " ',',\n",
       " 'the',\n",
       " 'a',\n",
       " 'science',\n",
       " 'calculated',\n",
       " ',',\n",
       " ')',\n",
       " '.',\n",
       " 'whitish',\n",
       " 'giant',\n",
       " '@-@',\n",
       " ',',\n",
       " 'by',\n",
       " 'separate',\n",
       " 'as',\n",
       " \"'s\",\n",
       " 'project',\n",
       " 'Noticing',\n",
       " 'to',\n",
       " 'suspicious',\n",
       " 'Gottschalk',\n",
       " 'expedition',\n",
       " 'Lorenz',\n",
       " 'diving',\n",
       " 'the',\n",
       " 'song',\n",
       " '.',\n",
       " 'hoped',\n",
       " 'RAAF',\n",
       " 'Southern',\n",
       " 'recognizing',\n",
       " '250',\n",
       " 'fighting',\n",
       " 'of',\n",
       " 'had',\n",
       " 'Welsh',\n",
       " 'Warbrick',\n",
       " 'to',\n",
       " 'as',\n",
       " ',',\n",
       " 'to',\n",
       " 'and',\n",
       " 'military',\n",
       " 'me',\n",
       " '60',\n",
       " 'episode',\n",
       " '360',\n",
       " 'topography',\n",
       " '@-@',\n",
       " 'the',\n",
       " '@-@',\n",
       " 'declined',\n",
       " 'Maya',\n",
       " 'team',\n",
       " ',',\n",
       " 'and',\n",
       " 'by',\n",
       " 'to',\n",
       " '.',\n",
       " 'Hill',\n",
       " '@-@',\n",
       " 'in',\n",
       " 'I',\n",
       " 'song',\n",
       " '110',\n",
       " 'people',\n",
       " 'barometric',\n",
       " 'of',\n",
       " 'its',\n",
       " 'year',\n",
       " 'and',\n",
       " '.',\n",
       " 'area',\n",
       " 'regeneration',\n",
       " 'used',\n",
       " 'the',\n",
       " 'produced',\n",
       " 'Walter',\n",
       " 'then',\n",
       " 'a',\n",
       " 'brothers',\n",
       " ']',\n",
       " 'a',\n",
       " '@-@',\n",
       " 'a',\n",
       " 'Dance',\n",
       " 'if',\n",
       " 'The',\n",
       " 'severe',\n",
       " 'immediately',\n",
       " 'At',\n",
       " 'their',\n",
       " 'to',\n",
       " 'an',\n",
       " 'complete',\n",
       " 'his',\n",
       " 'classic',\n",
       " 'total',\n",
       " 'of',\n",
       " 'have',\n",
       " 'having',\n",
       " ',',\n",
       " 'Turner',\n",
       " '24',\n",
       " 'of',\n",
       " 'Floor',\n",
       " 'old',\n",
       " 'halted',\n",
       " 'the',\n",
       " 'positions',\n",
       " 'of',\n",
       " 'Taare',\n",
       " '@,@',\n",
       " 'Battalion',\n",
       " ',',\n",
       " 'they',\n",
       " 'as',\n",
       " 'mountain',\n",
       " 'it',\n",
       " '@-@',\n",
       " ',',\n",
       " 'Deangelo',\n",
       " 'the',\n",
       " '.',\n",
       " 'Dynasty',\n",
       " 'and',\n",
       " \"'ll\",\n",
       " ',',\n",
       " 'disbanded',\n",
       " 'a',\n",
       " '\"',\n",
       " 'massive',\n",
       " 'a',\n",
       " ')',\n",
       " 'English',\n",
       " 'but',\n",
       " 'do',\n",
       " 'belonged',\n",
       " 'though',\n",
       " '(',\n",
       " ',',\n",
       " 'finalize',\n",
       " 'entering',\n",
       " 'in',\n",
       " 'of',\n",
       " 'Bellecourt',\n",
       " 'Electric',\n",
       " ',',\n",
       " 'the',\n",
       " 'exposed',\n",
       " 'right',\n",
       " 'There',\n",
       " ',',\n",
       " 'during',\n",
       " 'ringside',\n",
       " 'up',\n",
       " '<unk>',\n",
       " 'for',\n",
       " 'a',\n",
       " '<unk>',\n",
       " '\"',\n",
       " 'entire',\n",
       " 'with',\n",
       " '<unk>',\n",
       " \"'s\",\n",
       " 'Smith',\n",
       " 'Late',\n",
       " ',',\n",
       " 'position',\n",
       " '.',\n",
       " 'squadron',\n",
       " 'area',\n",
       " 'in',\n",
       " 'mass',\n",
       " 'jet',\n",
       " 'highway',\n",
       " 'In',\n",
       " 'to',\n",
       " '64',\n",
       " ',',\n",
       " '@-@',\n",
       " '.',\n",
       " 'called',\n",
       " ',',\n",
       " 'cut',\n",
       " 'Michigan',\n",
       " 'their',\n",
       " 'by',\n",
       " 'after',\n",
       " 'all',\n",
       " '<eos>',\n",
       " ',',\n",
       " '6',\n",
       " 'his',\n",
       " 'classes',\n",
       " ',',\n",
       " '@,@',\n",
       " \"'s\",\n",
       " ';',\n",
       " '.',\n",
       " 'was',\n",
       " 'Paul',\n",
       " 'instead',\n",
       " 'I',\n",
       " 'kilograms',\n",
       " 'the',\n",
       " 'decline',\n",
       " '<eos>',\n",
       " 'seized',\n",
       " 'a',\n",
       " 'that',\n",
       " 'September',\n",
       " '&',\n",
       " 'not',\n",
       " 'the',\n",
       " 'Boston',\n",
       " 'division',\n",
       " 'through',\n",
       " 'of',\n",
       " 'and',\n",
       " 'and',\n",
       " 'in',\n",
       " 'with',\n",
       " 'generally',\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "corpus.vocab.get_symbols(nll_over_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, lxml, re\n",
    "from lxml import etree\n",
    "\n",
    "# clean the input\n",
    "def clean(l):\n",
    "    l = l.replace('<size=-1>','')\n",
    "    l = l.replace('</size>','')\n",
    "    l = l.replace('<br>','')\n",
    "    l = l.replace('&','&amp;')\n",
    "    l = l.replace('\"<\"','&lt;')\n",
    "    l = l.replace('\">\"','&gt;')\n",
    "    return l.rstrip(',;\\n') + '\\n'\n",
    "\n",
    "# get information from the xml\n",
    "def headword(class_element):\n",
    "    return re.sub('[0-9#\\[\\] ]','',class_element.find(\"headword\").find(\"b\").text)\n",
    "\n",
    "def pos(pos_element):\n",
    "    return re.sub('[.#]','',pos_element.find(\"b\").text)\n",
    "\n",
    "def words(paragraph_element):\n",
    "    return set([word.strip() for i in paragraph_element \n",
    "           if not i.text is None \n",
    "           for word in i.text.split(',') \n",
    "           if not word == ' '\n",
    "           ])\n",
    "\n",
    "def index(fn,root):\n",
    "    return re.sub('[/heads.txt]','',fn + ' ') + headword(root)\n",
    "\n",
    "# helper generator:\n",
    "def pospargen(c):\n",
    "    for a,b in [c[x:x+2] for x in range(len(c)-1)]:\n",
    "        if a.tag == 'pos' and b.tag == 'paragraph':\n",
    "            yield [a,b]\n",
    "\n",
    "# get list of [POS, [words,in,entry]]\n",
    "def pos_words(c):\n",
    "    return dict([[pos(a),words(b)] for a,b in pospargen(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roget = {}\n",
    "\n",
    "for fn in glob.glob(\"./roget/heads/head*.txt\"):\n",
    "    with open(fn,'r',encoding=\"windows-1252\") as f:\n",
    "        xml = ['<class>']+[clean(l) for l in f.readlines()]+['</class>']\n",
    "        root = etree.fromstring(''.join(xml), parser=etree.XMLParser(encoding=\"windows-1252\"))\n",
    "        roget[index(fn,root)] = pos_words(root.getchildren())\n",
    "\n",
    "parts_of_speech = ['INT', 'VB', 'ADJ', 'N']\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "reverse_roget = defaultdict(set)\n",
    "for category in roget:\n",
    "    for pos in parts_of_speech:\n",
    "        if pos in roget[category]:\n",
    "            for word in roget[category][pos]:\n",
    "                reverse_roget[word + '_' + pos].add(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlls = np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_roget_dict = {}\n",
    "for k,v in roget.items():\n",
    "    encoded_pos_dict = {}\n",
    "    for k_pos, word_set in v.items():\n",
    "        encoded_set = set()\n",
    "        for word in word_set:\n",
    "            if word in corpus.vocab.sym2idx:\n",
    "                encoded_set.add(corpus.vocab.sym2idx[word])\n",
    "        encoded_pos_dict[k_pos] = encoded_set\n",
    "    encoded_roget_dict[k] = encoded_pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'N': {17956, 25458, 69389, 81721, 140717},\n",
       " 'VB': {10901, 44930, 57544, 97448, 180515},\n",
       " 'ADJ': {16318, 51645, 58464, 61463, 77647, 83160},\n",
       " 'ADV': {21478, 113881, 141177},\n",
       " 'INT': set()}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "encoded_roget_dict['rog871 Regret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppl_freq(encoded_roget_dict, pos_tag=\"N\",df=None):\n",
    "    if df is not None:\n",
    "        df[pos+'_ppl']=np.nan\n",
    "        df[pos+'_freq']=np.nan\n",
    "        df[pos+'_wordlist'] = ''\n",
    "        df[pos+'_wordfreq'] = ''\n",
    "        df[pos+'_avgfreq'] = np.nan\n",
    "    all_noun = []\n",
    "    noun_keys = []\n",
    "    for k,v in encoded_roget_dict.items():\n",
    "        if pos_tag in v:\n",
    "            noun_keys.append(k)\n",
    "            all_noun.append(v[pos_tag])\n",
    "    encoded_roget_pos_dict = {}\n",
    "    start_index = 0\n",
    "    for k in noun_keys:\n",
    "        current_word_set = encoded_roget_dict[k][pos]\n",
    "        end_index = start_index+ len(current_word_set)\n",
    "        remain_word_set = all_noun[:start_index]+all_noun[end_index:]\n",
    "        noun_set = []\n",
    "        for word in current_word_set:\n",
    "            if word not in remain_word_set:\n",
    "                noun_set.append(word)\n",
    "        start_index = end_index\n",
    "        encoded_roget_pos_dict[k] = noun_set\n",
    "    class_ppl = {}\n",
    "    class_freq = {}\n",
    "    \n",
    "    for k,v in encoded_roget_pos_dict.items():\n",
    "        word_list = []\n",
    "        wordfreq_list = []\n",
    "        freq = []\n",
    "        ppl = []\n",
    "        for word_id in v:\n",
    "            if word_id<=10000:\n",
    "                continue\n",
    "            word_list.append(corpus.vocab.idx2sym[word_id])\n",
    "            wordfreq_list.append(str(word_id))\n",
    "            indices = np.where(targets==word_id)[0]\n",
    "            for index in indices:\n",
    "                freq.append(word_id)\n",
    "                ppl_i = nlls[index]\n",
    "                ppl.append(ppl_i)\n",
    "        if df is not None and len(ppl)>0:\n",
    "            df[pos+'_wordlist'][df['class']==k] = ' '.join(word_list)\n",
    "            df[pos+'_wordfreq'][df['class']==k] = ' '.join(wordfreq_list)\n",
    "            df[pos+'_avgfreq'][df['class']==k] = np.mean(freq)\n",
    "            df[pos+'_ppl'][df['class']==k] = np.mean(ppl)\n",
    "            df[pos+'_freq'][df['class']==k] = len(ppl)\n",
    "        class_ppl[k] = np.mean(ppl)\n",
    "        class_freq[k] = len(ppl)\n",
    "    return class_ppl, class_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:45: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\nipykernel_launcher:46: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\nipykernel_launcher:47: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\nipykernel_launcher:48: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\nipykernel_launcher:49: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/home/baihe/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n  out=out, **kwargs)\n/home/baihe/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "class_df = pd.DataFrame({'class':list(encoded_roget_dict.keys())})\n",
    "class_df['name'] = [' '.join(k.split()[1:]) for k in class_df['class']]\n",
    "for pos in ['N','VB','ADJ']:\n",
    "    get_ppl_freq(encoded_roget_dict, pos,class_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            N_ppl      N_freq      N_avgfreq      VB_ppl     VB_freq     VB_avgfreq     ADJ_ppl    ADJ_freq    ADJ_avgfreq\n",
       "count  770.000000  770.000000     770.000000  493.000000  493.000000     493.000000  604.000000  604.000000     604.000000\n",
       "mean     9.677942    5.892208   24747.458609    9.481188    3.959432   25147.212721    9.566391    4.183775   24905.110897\n",
       "std      2.713695    6.758519   16042.489442    3.173086    3.677328   18292.187339    3.002031    3.907428   19113.299971\n",
       "min      1.582873    1.000000   10039.000000    0.056076    1.000000   10018.000000    0.433158    1.000000   10006.000000\n",
       "25%      8.123974    2.000000   16211.250000    7.837631    1.000000   15192.125000    7.792482    1.000000   15566.000000\n",
       "50%      9.676776    4.000000   20624.530303    9.535905    3.000000   19065.250000    9.648365    3.000000   19937.642857\n",
       "75%     11.145630    7.000000   27005.500000   11.144556    5.000000   27997.000000   11.277290    6.000000   28489.500000\n",
       "max     21.254297   59.000000  201381.000000   20.632851   20.000000  145572.000000   19.876669   33.000000  260308.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>N_ppl</th>\n      <th>N_freq</th>\n      <th>N_avgfreq</th>\n      <th>VB_ppl</th>\n      <th>VB_freq</th>\n      <th>VB_avgfreq</th>\n      <th>ADJ_ppl</th>\n      <th>ADJ_freq</th>\n      <th>ADJ_avgfreq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>count</td>\n      <td>770.000000</td>\n      <td>770.000000</td>\n      <td>770.000000</td>\n      <td>493.000000</td>\n      <td>493.000000</td>\n      <td>493.000000</td>\n      <td>604.000000</td>\n      <td>604.000000</td>\n      <td>604.000000</td>\n    </tr>\n    <tr>\n      <td>mean</td>\n      <td>9.677942</td>\n      <td>5.892208</td>\n      <td>24747.458609</td>\n      <td>9.481188</td>\n      <td>3.959432</td>\n      <td>25147.212721</td>\n      <td>9.566391</td>\n      <td>4.183775</td>\n      <td>24905.110897</td>\n    </tr>\n    <tr>\n      <td>std</td>\n      <td>2.713695</td>\n      <td>6.758519</td>\n      <td>16042.489442</td>\n      <td>3.173086</td>\n      <td>3.677328</td>\n      <td>18292.187339</td>\n      <td>3.002031</td>\n      <td>3.907428</td>\n      <td>19113.299971</td>\n    </tr>\n    <tr>\n      <td>min</td>\n      <td>1.582873</td>\n      <td>1.000000</td>\n      <td>10039.000000</td>\n      <td>0.056076</td>\n      <td>1.000000</td>\n      <td>10018.000000</td>\n      <td>0.433158</td>\n      <td>1.000000</td>\n      <td>10006.000000</td>\n    </tr>\n    <tr>\n      <td>25%</td>\n      <td>8.123974</td>\n      <td>2.000000</td>\n      <td>16211.250000</td>\n      <td>7.837631</td>\n      <td>1.000000</td>\n      <td>15192.125000</td>\n      <td>7.792482</td>\n      <td>1.000000</td>\n      <td>15566.000000</td>\n    </tr>\n    <tr>\n      <td>50%</td>\n      <td>9.676776</td>\n      <td>4.000000</td>\n      <td>20624.530303</td>\n      <td>9.535905</td>\n      <td>3.000000</td>\n      <td>19065.250000</td>\n      <td>9.648365</td>\n      <td>3.000000</td>\n      <td>19937.642857</td>\n    </tr>\n    <tr>\n      <td>75%</td>\n      <td>11.145630</td>\n      <td>7.000000</td>\n      <td>27005.500000</td>\n      <td>11.144556</td>\n      <td>5.000000</td>\n      <td>27997.000000</td>\n      <td>11.277290</td>\n      <td>6.000000</td>\n      <td>28489.500000</td>\n    </tr>\n    <tr>\n      <td>max</td>\n      <td>21.254297</td>\n      <td>59.000000</td>\n      <td>201381.000000</td>\n      <td>20.632851</td>\n      <td>20.000000</td>\n      <td>145572.000000</td>\n      <td>19.876669</td>\n      <td>33.000000</td>\n      <td>260308.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 307
    }
   ],
   "source": [
    "class_df.describe(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_n = (class_df['N_freq']>10) # &((class_df['N_ppl']<7)|(class_df['N_ppl']>11))\n",
    "noun_class_df = class_df[index_of_n].sort_values(by='N_freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_head_tail_n_pos_class(df,pos_tag, num):\n",
    "    class_df = df[(df[pos_tag+'_freq']>10)]\n",
    "    print('%s hard class %d:' % (pos_tag, num))\n",
    "    print(class_df.sort_values(by=pos_tag+'_ppl',ascending=False).head(num)[['name',pos_tag+'_wordlist',pos_tag+'_avgfreq',pos_tag+'_ppl']])\n",
    "    print('\\n%s easy class %d:' % (pos_tag, num))\n",
    "    print(class_df[class_df[pos_tag+'_ppl']>0].sort_values(by=pos_tag+'_ppl').head(num)[['name',pos_tag+'_wordlist',pos_tag+'_avgfreq',pos_tag+'_ppl']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.options.display.max_colwidth = 30\n",
    " pd.options.display.width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "N hard class 10:\n               name                     N_wordlist     N_avgfreq      N_ppl\n631        Activity  dispatch zealot ado meddli...  26547.416667  11.731858\n269            Love  eros fervor fondness darli...  23337.800000  11.490992\n539        Evildoer  savage barbarian oppressor...  33008.428571  11.474117\n101       Inclosure  ditch railing barricade co...  19198.272727  11.456427\n254        Property  folkland paraphernalia fie...  22237.500000  11.442895\n771       Deception  flytrap bait spoof hoax ti...  40407.083333  11.414145\n447      Instrument  helm oar harness paraphern...  32706.666667  11.372717\n724  Representation  likeness personification s...  16693.437500  11.289961\n982        Painting  enamel holograph portraitu...  15810.250000  11.225190\n74             Hope  buoyancy assumption cheer ...  21529.363636  11.187591\n\nN easy class 10:\n              name                     N_wordlist     N_avgfreq     N_ppl\n1015  Unimportance  rubbish weed refuse nonent...  20289.230769  7.191500\n365        Opening  piercing postern doorway s...  21406.833333  7.273566\n568          Store  hoard heap fountain mow de...  23347.037037  7.718702\n41           Class  subtype denomination assor...  16394.375000  7.777653\n915      Smallness  chip smack moderation mite...  16992.642857  7.825343\n822       Pleasure  comfort zest enchantment c...  20370.250000  7.941984\n311        Disease  cachexia leukemia tetanus ...  20596.687500  8.127315\n710       Crossing  anastomosis linen trellis ...  19349.166667  8.149552\n779        Writing  fist blackboard handwritin...  27523.333333  8.157739\n5             Plan  strategist schemer promote...  24194.285714  8.295078\n"
     ]
    }
   ],
   "source": [
    "print_head_tail_n_pos_class(class_df,'N',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VB hard class 10:\n                name                    VB_wordlist    VB_avgfreq     VB_ppl\n49        Excitation  fascinate excite pique inf...  18351.705882  12.116376\n658       Resentment  excite pique inflame fret ...  22577.181818  11.587866\n736           Motive  lure incite fascinate urge...  19128.923077  11.433347\n997        Cleanness  comb scrub weed sponge def...  23554.454545  11.263761\n1029       Hindrance  hustle barricade inhibit m...  36810.066667  11.000488\n850         Ejection  excrete dispatch spurt dro...  22439.071429  10.786085\n251        Falsehood  deceive invent feign quibb...  36049.384615  10.581319\n724   Representation  likeness illustrate statue...  22214.500000  10.402710\n1011      Disclosure  snitch uncover concede div...  32359.583333  10.305008\n869        Agitation  hustle ferment jerk hitch ...  31026.250000  10.251559\n\nVB easy class 10:\n            name                    VB_wordlist    VB_avgfreq    VB_ppl\n559    Restraint  suppress inhibit cloister ...  28695.285714  7.935778\n757     Location  bivouac shelve encamp crad...  18476.066667  7.941724\n771    Deception  lure spoof deceive overrea...  29158.090909  8.151625\n213  Affirmation  profess contend depose vou...  17670.933333  8.164778\n375     Junction  leash bracket harness sold...  19782.950000  8.363753\n776      Killing  dispatch slay behead slaug...  17270.882353  8.370915\n222    Impotence  prostrate invalidate hamst...  23358.571429  8.476261\n53      Slowness  grovel relax mince slacken...  55600.250000  8.523183\n107       Assent  concede reciprocate accede...  14995.909091  8.551975\n331   Moderation  slacken temper tame mitiga...  27666.800000  8.902299\n"
     ]
    }
   ],
   "source": [
    "print_head_tail_n_pos_class(class_df,'VB',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ADJ hard class 10:\n              name                   ADJ_wordlist   ADJ_avgfreq    ADJ_ppl\n574       Dullness  pedestrian stupid stolid p...  31788.454545  12.665000\n631       Activity  afoot workaday instant med...  30845.214286  12.619541\n209    Ostentation  punctilious flaunting flas...  21473.454545  12.112767\n183       Ugliness  forbidding grisly gaunt un...  31005.727273  12.049217\n804    Drunkenness  maudlin drunken corned boo...  26872.000000  11.510492\n485     Importance  weighty instant stirring c...  26125.181818  11.422877\n103           Vice  lax sinister corrupt sinfu...  25509.545455  11.143114\n332           Fear  apprehensive horrific trem...  17242.714286  11.101037\n57     Uncleanness  beastly corrupt moldy deca...  18354.909091  10.715285\n1015  Unimportance  respectable miserable scur...  18628.875000  10.449393\n\nADJ easy class 10:\n                 name                   ADJ_wordlist   ADJ_avgfreq   ADJ_ppl\n897              Land  alluvial littoral earthy m...  26614.000000  6.293205\n401           Feeling  hearty emotive incisive si...  21829.785714  7.415765\n118      Disagreement  antagonistic uncongenial d...  18048.769231  7.645802\n578    Unskillfulness  stupid unhandy unused gidd...  15901.363636  7.703135\n812      Inexpedience  inconvenient awkward cumbe...  20480.166667  7.937528\n686   Pleasurableness  halcyon pleasing ravishing...  20689.933333  8.246426\n222         Impotence  shattered crippled inept p...  22725.076923  8.255210\n1018     Unconformity  heterogeneous teratogenic ...  17556.727273  8.459433\n177           Oldness  Cenozoic Cambrian Jurassic...  19835.619048  8.540053\n684           Badness  harmful detrimental sinist...  17676.571429  8.661314\n"
     ]
    }
   ],
   "source": [
    "print_head_tail_n_pos_class(class_df,'ADJ',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}